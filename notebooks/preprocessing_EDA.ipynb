{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa492eb2",
   "metadata": {},
   "source": [
    "# Data Analysis Notebook\n",
    "\n",
    "This notebook combines data collection (scraping) and data preprocessing.\n",
    "\n",
    "Steps:\n",
    "1. **Scrape** reviews from Google Play Store\n",
    "2. **Preprocess** and clean the data\n",
    "3. **Visualize** the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285f1df",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'week2 (Python 3.10.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/elbethelzewdie/Documents/customer-satisfaction-week2/customer-satisfaction-week2/week2/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "# Check if we need to change directory to the project root\n",
    "if os.path.basename(current_dir) == 'Scripts':\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "    os.chdir(project_root)\n",
    "    print(f\"Changed working directory to: {project_root}\")\n",
    "    sys.path.append(current_dir)\n",
    "else:\n",
    "    scripts_path = os.path.join(current_dir, 'Scripts')\n",
    "    if os.path.exists(scripts_path):\n",
    "        sys.path.append(scripts_path)\n",
    "\n",
    "# Import modules\n",
    "try:\n",
    "    from preprocessing import ReviewPreprocessor\n",
    "    try:\n",
    "        from scraper import main as run_scraper\n",
    "    except ImportError:\n",
    "        from scraper import main as run_scraper\n",
    "except ImportError as e:\n",
    "    # Fallback logic if imports fail directly\n",
    "    sys.path.append(os.getcwd())\n",
    "    from preprocessing import ReviewPreprocessor\n",
    "    from scraper import main as run_scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1dc73",
   "metadata": {},
   "source": [
    "## 1. Run Scraper\n",
    "\n",
    "This cell runs the scraping script to fetch the latest reviews from the Google Play Store.\n",
    "The output will show the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Scraper...\")\n",
    "\n",
    "# Run the main scraper function\n",
    "raw_df = run_scraper()\n",
    "\n",
    "print(\"\\n‚úÖ Scraping Finished.\")\n",
    "display(raw_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a875c4e",
   "metadata": {},
   "source": [
    "## 2. Run Preprocessing Pipeline\n",
    "\n",
    "Now we clean the scraped data using our `ReviewPreprocessor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the preprocessor\n",
    "preprocessor = ReviewPreprocessor()\n",
    "\n",
    "# Run the process\n",
    "success = preprocessor.process()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚úÖ Preprocessing finished successfully!\")\n",
    "    df = preprocessor.df\n",
    "else:\n",
    "    print(\"‚ùå Preprocessing failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21cd90c",
   "metadata": {},
   "source": [
    "## 3. Visualizations\n",
    "\n",
    "Let's explore the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 1. Ratings Distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='rating', data=df, palette='viridis')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# 2. Reviews per Bank\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='bank_code', data=df, palette='Set2')\n",
    "plt.title('Number of Reviews per Bank')\n",
    "plt.xlabel('Bank')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Review Length Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='text_length', bins=50, kde=True, hue='bank_code')\n",
    "plt.title('Distribution of Review Lengths by Bank')\n",
    "plt.xlabel('Review Length (characters)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68d389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
